{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines\n",
    "#1269748302142042113 is last tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at=[]\n",
    "id=[]\n",
    "full_text=[]\n",
    "coordinates=[]\n",
    "lang=[]\n",
    "location=[]\n",
    "place=[]\n",
    "with jsonlines.open('/Users/sam/Documents/Masters/Data_Systems_Project/Large files/blm_part3.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        location.append(obj['user']['location'])\n",
    "        place.append(obj['place'])\n",
    "        created_at.append(obj['created_at'])\n",
    "        id.append(obj['id'])\n",
    "        full_text.append(obj['full_text'])\n",
    "        coordinates.append(obj['coordinates'])\n",
    "        lang.append(obj['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "tweets['created_at']= created_at\n",
    "tweets['id']= id\n",
    "tweets['text']= full_text\n",
    "tweets['coordinates']= coordinates\n",
    "tweets['lang']= lang\n",
    "tweets['place'] = place\n",
    "tweets['user_location']= location"
   ]
  },
  {
   "source": [
    "## change user dependent location"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length before: 7365723\n",
      "length after: 914749\n"
     ]
    }
   ],
   "source": [
    "print('length before:', len(tweets))\n",
    "def comma_locate(x):\n",
    "    x = x[-4:-2]\n",
    "    return x\n",
    "tweets = tweets[tweets['user_location'].map(comma_locate) == ', ']\n",
    "print('length after:', len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cities = pd.read_csv(\"us_cities_states_counties.csv\", delimiter = \"|\")\n",
    "#cities['location'] = cities.City.map(str) + \", \" + cities['State short']\n",
    "#cities = cities['location'].drop_duplicates()\n",
    "#cities = cities.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('......csv')"
   ]
  },
  {
   "source": [
    "### Make 1 dataset from the three\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = pd.read_csv(\"/Users/sam/Documents/Masters/Data_Systems_Project/Locations/user_locations_1.csv\")\n",
    "tweets2 = pd.read_csv(\"/Users/sam/Documents/Masters/Data_Systems_Project/Locations/user_locations_2.csv\")\n",
    "tweets3 = pd.read_csv(\"/Users/sam/Documents/Masters/Data_Systems_Project/Locations/user_locations_3.csv\")\n",
    "tweets = tweets1.append([tweets2, tweets3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('user_locations.csv')"
   ]
  },
  {
   "source": [
    "## Change tweet dependent location"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index(drop=True)\n",
    "tweets['tweet_location'] = 'None'\n",
    "tweets['tweet_country'] = 'None'\n",
    "for idx, val in enumerate(tweets['place']):\n",
    "        tweets['tweet_location'][idx] = val['full_name']\n",
    "        tweets['tweet_country'][idx] = val['country_code']\n",
    "tweets = tweets.drop(columns=['place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length before:', len(tweets))\n",
    "tweets = tweets[(tweets['country'] == \"US\")]\n",
    "print('length after:', len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length before:', len(tweets))\n",
    "tweets = tweets[pd.notnull(tweets['coordinates'])]\n",
    "print('length after:', len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_json(',,,,,.json')"
   ]
  }
 ]
}